---
title: Mains et contrôleurs de mouvement dans DirectX
description: Prise en main du Guide du développeur pour utiliser le suivi de la main et les contrôleurs de mouvement dans les applications DirectX natives.
author: caseymeekhof
ms.author: cmeekhof
ms.date: 08/04/2020
ms.topic: article
keywords: mains, contrôleurs de mouvement, DirectX, entrée, hologrammes, casque de réalité mixte, casque de réalité mixte, casque de réalité virtuelle
ms.openlocfilehash: 43673602b01a1937953d16fcca9b4c4f4d3fd33a
ms.sourcegitcommit: 2329db5a76dfe1b844e21291dbc8ee3888ed1b81
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 01/08/2021
ms.locfileid: "98009539"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="461fd-104">Mains et contrôleurs de mouvement dans DirectX</span><span class="sxs-lookup"><span data-stu-id="461fd-104">Hands and motion controllers in DirectX</span></span>

> [!NOTE]
> <span data-ttu-id="461fd-105">Cet article s’applique aux API natives WinRT héritées.</span><span class="sxs-lookup"><span data-stu-id="461fd-105">This article relates to the legacy WinRT native APIs.</span></span>  <span data-ttu-id="461fd-106">Pour les nouveaux projets d’application native, nous vous recommandons d’utiliser l' **[API OpenXR](openxr-getting-started.md)**.</span><span class="sxs-lookup"><span data-stu-id="461fd-106">For new native app projects, we recommend using the **[OpenXR API](openxr-getting-started.md)**.</span></span>

<span data-ttu-id="461fd-107">Dans Windows Mixed Reality, les entrées de la main et du [contrôleur de mouvement](../../design/motion-controllers.md) sont gérées via les API d’entrée spatiale, qui se trouvent dans l’espace de noms [Windows. UI. Input. spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) .</span><span class="sxs-lookup"><span data-stu-id="461fd-107">In Windows Mixed Reality, both hand and [motion controller](../../design/motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="461fd-108">Cela vous permet de gérer facilement des actions courantes telles que la **sélection** de la même façon sur les deux mains et les contrôleurs de mouvement.</span><span class="sxs-lookup"><span data-stu-id="461fd-108">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="461fd-109">Prise en main</span><span class="sxs-lookup"><span data-stu-id="461fd-109">Getting started</span></span>

<span data-ttu-id="461fd-110">Pour accéder aux entrées spatiales dans Windows Mixed Reality, commencez par l’interface SpatialInteractionManager.</span><span class="sxs-lookup"><span data-stu-id="461fd-110">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="461fd-111">Vous pouvez accéder à cette interface en appelant  [SpatialInteractionManager :: GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), généralement au cours du démarrage de l’application.</span><span class="sxs-lookup"><span data-stu-id="461fd-111">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="461fd-112">Le travail du SpatialInteractionManager consiste à fournir l’accès à [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource), qui représente une source d’entrée.</span><span class="sxs-lookup"><span data-stu-id="461fd-112">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="461fd-113">Il existe trois types de SpatialInteractionSources disponibles dans le système.</span><span class="sxs-lookup"><span data-stu-id="461fd-113">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="461fd-114">La **main** représente la main détectée d’un utilisateur.</span><span class="sxs-lookup"><span data-stu-id="461fd-114">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="461fd-115">Les sources de main offrent différentes fonctionnalités basées sur l’appareil, allant des gestes de base sur HoloLens au suivi complet sur HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="461fd-115">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="461fd-116">Le **contrôleur** représente un contrôleur de mouvement jumelé.</span><span class="sxs-lookup"><span data-stu-id="461fd-116">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="461fd-117">Les contrôleurs de mouvement peuvent offrir des fonctionnalités différentes, par exemple, sélectionner des déclencheurs, des boutons de menu, des boutons, des pavés tactiles et des Thumbsticks.</span><span class="sxs-lookup"><span data-stu-id="461fd-117">Motion controllers can offer different capabilities, for example, Select triggers, Menu buttons, Grasp buttons, touchpads, and thumbsticks.</span></span>
* <span data-ttu-id="461fd-118">La **voix** représente les mots-clés détectés par le système vocal de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="461fd-118">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="461fd-119">Par exemple, cette source injecte une pression SELECT et une mise en sortie chaque fois que l’utilisateur dit « Select ».</span><span class="sxs-lookup"><span data-stu-id="461fd-119">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="461fd-120">Les données par trame pour une source sont représentées par l’interface  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) .</span><span class="sxs-lookup"><span data-stu-id="461fd-120">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="461fd-121">Il existe deux façons d’accéder à ces données, selon que vous souhaitez utiliser un modèle piloté par des événements ou basé sur l’interrogation dans votre application.</span><span class="sxs-lookup"><span data-stu-id="461fd-121">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="461fd-122">Entrée pilotée par les événements</span><span class="sxs-lookup"><span data-stu-id="461fd-122">Event-driven input</span></span>
<span data-ttu-id="461fd-123">SpatialInteractionManager fournit un certain nombre d’événements que votre application peut écouter.</span><span class="sxs-lookup"><span data-stu-id="461fd-123">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="461fd-124">Voici quelques exemples :   [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased et [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span><span class="sxs-lookup"><span data-stu-id="461fd-124">A few examples include   [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased, and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="461fd-125">Par exemple, le code suivant raccorde un gestionnaire d’événements appelé MyApp :: OnSourcePressed à l’événement SourcePressed.</span><span class="sxs-lookup"><span data-stu-id="461fd-125">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="461fd-126">Cela permet à votre application de détecter les presses sur n’importe quel type de source d’interaction.</span><span class="sxs-lookup"><span data-stu-id="461fd-126">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="461fd-127">Cet événement appuyé est envoyé à votre application de manière asynchrone, avec les SpatialInteractionSourceState correspondants au moment où la pression s’est produite.</span><span class="sxs-lookup"><span data-stu-id="461fd-127">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="461fd-128">Votre application ou moteur de jeu peut souhaiter commencer à traiter immédiatement ou placer en file d’attente les données d’événement dans votre routine de traitement d’entrée.</span><span class="sxs-lookup"><span data-stu-id="461fd-128">Your app or game engine may want to start processing right away or queue up the event data in your input processing routine.</span></span> <span data-ttu-id="461fd-129">Voici une fonction de gestionnaire d’événements pour l’événement SourcePressed, qui vérifie si le bouton Sélectionner a été enfoncé.</span><span class="sxs-lookup"><span data-stu-id="461fd-129">Here's an event handler function for the SourcePressed event, which checks whether the select button has been pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="461fd-130">Le code ci-dessus vérifie uniquement l’appui sur « Select », qui correspond à l’action principale sur l’appareil.</span><span class="sxs-lookup"><span data-stu-id="461fd-130">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="461fd-131">Les exemples incluent la réalisation d’un AirTap sur HoloLens ou l’extraction du déclencheur sur un contrôleur de mouvement.</span><span class="sxs-lookup"><span data-stu-id="461fd-131">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="461fd-132">Les presses « Select » représentent l’intention de l’utilisateur d’activer l’hologramme qu’il cible.</span><span class="sxs-lookup"><span data-stu-id="461fd-132">'Select' presses represent the user's intention to activate the hologram they're targeting.</span></span>  <span data-ttu-id="461fd-133">L’événement SourcePressed se déclenche pour un certain nombre de boutons et de mouvements différents. vous pouvez inspecter les autres propriétés sur le SpatialInteractionSource pour tester ces cas-là.</span><span class="sxs-lookup"><span data-stu-id="461fd-133">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="461fd-134">Entrée basée sur l’interrogation</span><span class="sxs-lookup"><span data-stu-id="461fd-134">Polling-based input</span></span>
<span data-ttu-id="461fd-135">Vous pouvez également utiliser SpatialInteractionManager pour interroger l’état actuel de l’entrée dans chaque cadre.</span><span class="sxs-lookup"><span data-stu-id="461fd-135">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="461fd-136">Pour ce faire, appelez [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) chaque frame.</span><span class="sxs-lookup"><span data-stu-id="461fd-136">To do this, call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="461fd-137">Cette fonction retourne un tableau contenant un [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) pour chaque [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource)actif.</span><span class="sxs-lookup"><span data-stu-id="461fd-137">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="461fd-138">Cela signifie un pour chaque contrôleur de mouvement actif, un pour chaque main suivie et un pour la parole si une commande « Select » a été récemment mise en circulation.</span><span class="sxs-lookup"><span data-stu-id="461fd-138">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="461fd-139">Vous pouvez ensuite inspecter les propriétés sur chaque SpatialInteractionSourceState pour piloter l’entrée dans votre application.</span><span class="sxs-lookup"><span data-stu-id="461fd-139">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="461fd-140">Voici un exemple de vérification de l’action « Select » à l’aide de la méthode d’interrogation.</span><span class="sxs-lookup"><span data-stu-id="461fd-140">Here's an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="461fd-141">La variable de *prédiction* représente un objet [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) , qui peut être obtenu à partir du [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="461fd-141">The *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com//uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="461fd-142">Chaque SpatialInteractionSource a un ID, que vous pouvez utiliser pour identifier les nouvelles sources et mettre en corrélation les sources existantes d’une image à l’autre.</span><span class="sxs-lookup"><span data-stu-id="461fd-142">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="461fd-143">Les mains reçoivent un nouvel ID à chaque fois qu’ils sortent et entrent dans l’angle de la connexion, mais les ID de contrôleur restent statiques pendant la durée de la session.</span><span class="sxs-lookup"><span data-stu-id="461fd-143">Hands get a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="461fd-144">Vous pouvez utiliser les événements sur SpatialInteractionManager tels que [SourceDetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) et [SourceLost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), pour réagir quand les mains entrent ou quittent la vue de l’appareil, ou lorsque les contrôleurs de mouvement sont activés/désactivés ou sont jumelés/non couplés.</span><span class="sxs-lookup"><span data-stu-id="461fd-144">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="461fd-145">Différences entre les poses prédites et l’historique</span><span class="sxs-lookup"><span data-stu-id="461fd-145">Predicted vs. historical poses</span></span>
<span data-ttu-id="461fd-146">GetDetectedSourcesAtTimestamp a un paramètre timestamp.</span><span class="sxs-lookup"><span data-stu-id="461fd-146">GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="461fd-147">Cela vous permet de demander l’État et de créer des données qui sont prédites ou historiques, ce qui vous permet de mettre en corrélation les interactions spatiales avec d’autres sources d’entrée.</span><span class="sxs-lookup"><span data-stu-id="461fd-147">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="461fd-148">Par exemple, lors du rendu de la position de la main dans le frame actuel, vous pouvez transmettre l’horodatage prédit fourni par [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span><span class="sxs-lookup"><span data-stu-id="461fd-148">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="461fd-149">Cela permet au système de prédire la position de la main pour s’aligner étroitement avec la sortie du frame rendu, réduisant ainsi la latence perçue.</span><span class="sxs-lookup"><span data-stu-id="461fd-149">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="461fd-150">Toutefois, une telle pose prédite ne produit pas un rayon de pointage idéal pour le ciblage avec une source d’interaction.</span><span class="sxs-lookup"><span data-stu-id="461fd-150">However, such a predicted pose doesn't produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="461fd-151">Par exemple, quand vous appuyez sur un bouton de contrôleur de mouvement, il peut falloir jusqu’à 20 ms pour que cet événement se propage via Bluetooth au système d’exploitation.</span><span class="sxs-lookup"><span data-stu-id="461fd-151">For example, when a motion controller button is pressed, it can take up to 20 ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="461fd-152">De même, une fois qu’un utilisateur a fait un mouvement manuel, un certain laps de temps peut s’écouler avant que le système ne détecte le geste et que votre application l’interroge.</span><span class="sxs-lookup"><span data-stu-id="461fd-152">Similarly, after a user does a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="461fd-153">Au moment où votre application interroge une modification d’État, les points de vue et de main sont utilisés pour cibler cette interaction qui s’est effectivement produite dans le passé.</span><span class="sxs-lookup"><span data-stu-id="461fd-153">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="461fd-154">Si vous ciblez en passant l’horodatage de votre HolographicFrame actuel à GetDetectedSourcesAtTimestamp, le pose sera au contraire prévisible dans le rayon cible au moment de l’affichage de l’image, ce qui peut être supérieur à 20 ms à l’avenir.</span><span class="sxs-lookup"><span data-stu-id="461fd-154">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20 ms in the future.</span></span> <span data-ttu-id="461fd-155">Ce nouveau point est idéal pour le *rendu* de la source d’interaction, mais il compose notre problème de temps pour *cibler* l’interaction, car le ciblage de l’utilisateur s’est produit dans le passé.</span><span class="sxs-lookup"><span data-stu-id="461fd-155">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="461fd-156">Heureusement, les événements [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased et [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) fournissent l' [État](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) historique associé à chaque événement d’entrée.</span><span class="sxs-lookup"><span data-stu-id="461fd-156">Fortunately, the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased, and [SourceUpdated](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="461fd-157">Cela comprend directement les mises à disposition de l’historique et des handles disponibles via [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), ainsi qu’un [horodateur](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) historique que vous pouvez transmettre à d’autres API pour établir une corrélation avec cet événement.</span><span class="sxs-lookup"><span data-stu-id="461fd-157">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="461fd-158">Cela entraîne les meilleures pratiques suivantes lors du rendu et du ciblage avec les mains et les contrôleurs de chaque cadre :</span><span class="sxs-lookup"><span data-stu-id="461fd-158">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="461fd-159">Pour le rendu de la **main/du contrôleur** de chaque trame, votre application doit **interroger** la partie **préprédite** de chaque source d’interaction au moment de la photonique du frame actuel.</span><span class="sxs-lookup"><span data-stu-id="461fd-159">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="461fd-160">Vous pouvez interroger toutes les sources d’interaction en appelant [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) chaque frame, en transmettant l’horodatage prédit fourni par [HolographicFrame :: CurrentPrediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span><span class="sxs-lookup"><span data-stu-id="461fd-160">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com//uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="461fd-161">Pour le ciblage de la **main/du contrôleur** sur une presse ou une mise en version, votre application doit gérer les **événements** appuyés/libérés, Raycasting en fonction de la position de l' **historique** ou de la main pour cet événement.</span><span class="sxs-lookup"><span data-stu-id="461fd-161">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="461fd-162">Pour ce faire, vous devez gérer l’événement [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) ou [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) , obtenir la propriété [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) à partir des arguments d’événement, puis appeler sa méthode [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) .</span><span class="sxs-lookup"><span data-stu-id="461fd-162">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="461fd-163">Propriétés d’entrée entre appareils</span><span class="sxs-lookup"><span data-stu-id="461fd-163">Cross-device input properties</span></span>
<span data-ttu-id="461fd-164">L’API SpatialInteractionSource prend en charge les contrôleurs et les systèmes de suivi de main avec un large éventail de fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="461fd-164">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="461fd-165">Un certain nombre de ces fonctionnalités sont communes entre les types d’appareils.</span><span class="sxs-lookup"><span data-stu-id="461fd-165">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="461fd-166">Par exemple, le suivi des mains et les contrôleurs de mouvement fournissent tous deux une action « sélectionner » et une position 3D.</span><span class="sxs-lookup"><span data-stu-id="461fd-166">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="461fd-167">Dans la mesure du possible, l’API mappe ces fonctionnalités communes aux mêmes propriétés sur le SpatialInteractionSource.</span><span class="sxs-lookup"><span data-stu-id="461fd-167">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="461fd-168">Cela permet aux applications de prendre en charge plus facilement un large éventail de types d’entrée.</span><span class="sxs-lookup"><span data-stu-id="461fd-168">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="461fd-169">Le tableau suivant décrit les propriétés prises en charge et leur comparaison entre les types d’entrée.</span><span class="sxs-lookup"><span data-stu-id="461fd-169">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="461fd-170">Propriété</span><span class="sxs-lookup"><span data-stu-id="461fd-170">Property</span></span> | <span data-ttu-id="461fd-171">Description</span><span class="sxs-lookup"><span data-stu-id="461fd-171">Description</span></span> | <span data-ttu-id="461fd-172">Gestes HoloLens (1ère génération)</span><span class="sxs-lookup"><span data-stu-id="461fd-172">HoloLens(1st gen) Gestures</span></span> | <span data-ttu-id="461fd-173">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="461fd-173">Motion Controllers</span></span> | <span data-ttu-id="461fd-174">Mains articulées</span><span class="sxs-lookup"><span data-stu-id="461fd-174">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="461fd-175">SpatialInteractionSource ::**main**</span><span class="sxs-lookup"><span data-stu-id="461fd-175">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="461fd-176">La main droite ou gauche/le contrôleur.</span><span class="sxs-lookup"><span data-stu-id="461fd-176">Right or left hand / controller.</span></span> | <span data-ttu-id="461fd-177">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-177">Not Supported</span></span> | <span data-ttu-id="461fd-178">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-178">Supported</span></span> | <span data-ttu-id="461fd-179">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-179">Supported</span></span> |
| [<span data-ttu-id="461fd-180">SpatialInteractionSourceState ::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="461fd-180">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="461fd-181">État actuel du bouton principal.</span><span class="sxs-lookup"><span data-stu-id="461fd-181">Current state of the primary button.</span></span> | <span data-ttu-id="461fd-182">Robinet d’air</span><span class="sxs-lookup"><span data-stu-id="461fd-182">Air Tap</span></span> | <span data-ttu-id="461fd-183">Déclencheur</span><span class="sxs-lookup"><span data-stu-id="461fd-183">Trigger</span></span> | <span data-ttu-id="461fd-184">Robinet à air lâche (pincement vertical)</span><span class="sxs-lookup"><span data-stu-id="461fd-184">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="461fd-185">SpatialInteractionSourceState ::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="461fd-185">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="461fd-186">État actuel du bouton de manipulation.</span><span class="sxs-lookup"><span data-stu-id="461fd-186">Current state of the grab button.</span></span> | <span data-ttu-id="461fd-187">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-187">Not Supported</span></span> | <span data-ttu-id="461fd-188">Bouton de manipulation</span><span class="sxs-lookup"><span data-stu-id="461fd-188">Grab button</span></span> | <span data-ttu-id="461fd-189">Pincer ou fermer la main</span><span class="sxs-lookup"><span data-stu-id="461fd-189">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="461fd-190">SpatialInteractionSourceState ::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="461fd-190">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="461fd-191">État actuel du bouton de menu.</span><span class="sxs-lookup"><span data-stu-id="461fd-191">Current state of the menu button.</span></span>    | <span data-ttu-id="461fd-192">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-192">Not Supported</span></span> | <span data-ttu-id="461fd-193">Bouton de menu</span><span class="sxs-lookup"><span data-stu-id="461fd-193">Menu Button</span></span> | <span data-ttu-id="461fd-194">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-194">Not Supported</span></span> |
| [<span data-ttu-id="461fd-195">SpatialInteractionSourceLocation ::**position**</span><span class="sxs-lookup"><span data-stu-id="461fd-195">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="461fd-196">Emplacement XYZ de la main ou de la position de la poignée sur le contrôleur.</span><span class="sxs-lookup"><span data-stu-id="461fd-196">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="461fd-197">Emplacement Palm</span><span class="sxs-lookup"><span data-stu-id="461fd-197">Palm location</span></span> | <span data-ttu-id="461fd-198">Poignée de pose position</span><span class="sxs-lookup"><span data-stu-id="461fd-198">Grip pose position</span></span> | <span data-ttu-id="461fd-199">Emplacement Palm</span><span class="sxs-lookup"><span data-stu-id="461fd-199">Palm location</span></span> |
| [<span data-ttu-id="461fd-200">SpatialInteractionSourceLocation ::**orientation**</span><span class="sxs-lookup"><span data-stu-id="461fd-200">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="461fd-201">Quaternion représentant l’orientation de la main ou de la poignée sur le contrôleur.</span><span class="sxs-lookup"><span data-stu-id="461fd-201">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="461fd-202">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-202">Not Supported</span></span> | <span data-ttu-id="461fd-203">Poignée d’orientation de pose</span><span class="sxs-lookup"><span data-stu-id="461fd-203">Grip pose orientation</span></span> | <span data-ttu-id="461fd-204">Orientation Palm</span><span class="sxs-lookup"><span data-stu-id="461fd-204">Palm orientation</span></span> |
| [<span data-ttu-id="461fd-205">SpatialPointerInteractionSourcePose ::**position**</span><span class="sxs-lookup"><span data-stu-id="461fd-205">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="461fd-206">Origine du rayon de pointage.</span><span class="sxs-lookup"><span data-stu-id="461fd-206">Origin of the pointing ray.</span></span> | <span data-ttu-id="461fd-207">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-207">Not Supported</span></span> | <span data-ttu-id="461fd-208">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-208">Supported</span></span> | <span data-ttu-id="461fd-209">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-209">Supported</span></span> |
| [<span data-ttu-id="461fd-210">SpatialPointerInteractionSourcePose ::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="461fd-210">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="461fd-211">Direction du rayon de pointage.</span><span class="sxs-lookup"><span data-stu-id="461fd-211">Direction of the pointing ray.</span></span> | <span data-ttu-id="461fd-212">Non pris en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-212">Not Supported</span></span> | <span data-ttu-id="461fd-213">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-213">Supported</span></span> | <span data-ttu-id="461fd-214">Prise en charge</span><span class="sxs-lookup"><span data-stu-id="461fd-214">Supported</span></span> |

<span data-ttu-id="461fd-215">Certaines des propriétés ci-dessus ne sont pas disponibles sur tous les appareils, et l’API fournit un moyen de les tester.</span><span class="sxs-lookup"><span data-stu-id="461fd-215">Some of the above properties aren't available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="461fd-216">Par exemple, vous pouvez inspecter la propriété [SpatialInteractionSource :: IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) pour déterminer si la source fournit une action saisissante.</span><span class="sxs-lookup"><span data-stu-id="461fd-216">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="461fd-217">Poignée de pose et pose de pointage</span><span class="sxs-lookup"><span data-stu-id="461fd-217">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="461fd-218">Windows Mixed Reality prend en charge les contrôleurs de mouvement dans différents facteurs de forme.</span><span class="sxs-lookup"><span data-stu-id="461fd-218">Windows Mixed Reality supports motion controllers in different form factors.</span></span>  <span data-ttu-id="461fd-219">Il prend également en charge les systèmes de suivi articulés.</span><span class="sxs-lookup"><span data-stu-id="461fd-219">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="461fd-220">Tous ces systèmes ont des relations différentes entre la position de la main et la direction « avant » naturelle que les applications doivent utiliser pour le pointage ou le rendu des objets dans la main de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="461fd-220">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendering objects in the user's hand.</span></span>  <span data-ttu-id="461fd-221">Pour prendre en charge tout cela, il existe deux types de poses 3D fournis pour le suivi des mains et les contrôleurs de mouvement.</span><span class="sxs-lookup"><span data-stu-id="461fd-221">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="461fd-222">La première est la poignée, qui représente la position de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="461fd-222">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="461fd-223">Le deuxième point de pose, qui représente un rayon de pointage provenant de la main ou du contrôleur de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="461fd-223">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="461fd-224">Par conséquent, si vous souhaitez afficher **la main de l’utilisateur** ou **un objet détenu par l’utilisateur**, tel qu’un épée ou un pistolet, utilisez la poignée.</span><span class="sxs-lookup"><span data-stu-id="461fd-224">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="461fd-225">Si vous souhaitez raycast du contrôleur ou de la main, par exemple quand l’utilisateur est \* \* pointant sur l’interface utilisateur, utilisez le point de pose.</span><span class="sxs-lookup"><span data-stu-id="461fd-225">If you want to raycast from the controller or hand, for example when the user is \*\*pointing at UI, use the pointing pose.</span></span>

<span data-ttu-id="461fd-226">Vous pouvez accéder à la **poignée** à l’aide de [SpatialInteractionSourceState ::P ropriétés :: TryGetLocation (...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_). Elle est définie comme suit :</span><span class="sxs-lookup"><span data-stu-id="461fd-226">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_). It's defined as follows:</span></span>
* <span data-ttu-id="461fd-227">Position de la **poignée**: le centre de la poche quand il maintient le contrôleur naturellement, ajusté à gauche ou à droite pour centrer la position au sein de la poignée.</span><span class="sxs-lookup"><span data-stu-id="461fd-227">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="461fd-228">**Axe droit de l’orientation de la poignée**: lorsque vous ouvrez complètement votre main pour former une pose plate à 5 doigts, le rayon normal à votre paume (en avant à partir de la poche de gauche, en arrière depuis la paume de droite)</span><span class="sxs-lookup"><span data-stu-id="461fd-228">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="461fd-229">**Axe avant de l’orientation de la poignée**: quand vous fermez partiellement votre main (comme si vous détenir le contrôleur), le rayon qui pointe vers l’avant dans le tube formé par vos doigts non thumbs.</span><span class="sxs-lookup"><span data-stu-id="461fd-229">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="461fd-230">**Axe vers le haut de l’orientation**: l’axe vers le haut, impliqué dans les définitions Right et Forward.</span><span class="sxs-lookup"><span data-stu-id="461fd-230">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="461fd-231">Vous pouvez accéder à la **pose du pointeur** par le biais de [SpatialInteractionSourceState ::P ropriétés :: TryGetLocation (...) :: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) ou [SpatialInteractionSourceState :: TryGetPointerPose (...) :: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span><span class="sxs-lookup"><span data-stu-id="461fd-231">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="461fd-232">Propriétés d’entrée spécifiques au contrôleur</span><span class="sxs-lookup"><span data-stu-id="461fd-232">Controller-specific input properties</span></span>
<span data-ttu-id="461fd-233">Pour les contrôleurs, SpatialInteractionSource a une propriété de contrôleur avec des fonctionnalités supplémentaires.</span><span class="sxs-lookup"><span data-stu-id="461fd-233">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="461fd-234">**HasThumbstick :** Si la valeur est true, le contrôleur a un stick analogique.</span><span class="sxs-lookup"><span data-stu-id="461fd-234">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="461fd-235">Inspectez la propriété [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) de SpatialInteractionSourceState pour obtenir les valeurs de stick analogique x et y (ThumbstickX et ThumbstickY), ainsi que l’état enfoncé (IsThumbstickPressed).</span><span class="sxs-lookup"><span data-stu-id="461fd-235">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="461fd-236">**HasTouchpad :** Si la valeur est true, le contrôleur a un pavé tactile.</span><span class="sxs-lookup"><span data-stu-id="461fd-236">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="461fd-237">Inspectez la propriété ControllerProperties de SpatialInteractionSourceState pour obtenir les valeurs de pavé tactile x et y (TouchpadX et touchpad), et pour savoir si l’utilisateur touche le bloc (IsTouchpadTouched) et s’il appuie sur le pavé tactile (IsTouchpadPressed).</span><span class="sxs-lookup"><span data-stu-id="461fd-237">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they're pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="461fd-238">**SimpleHapticsController :** L’API SimpleHapticsController pour le contrôleur vous permet d’inspecter les fonctionnalités haptique du contrôleur et vous permet également de contrôler les commentaires haptique.</span><span class="sxs-lookup"><span data-stu-id="461fd-238">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="461fd-239">La plage du pavé tactile et du stick analogique est comprise entre-1 et 1 pour les deux axes (de bas en haut et de gauche à droite).</span><span class="sxs-lookup"><span data-stu-id="461fd-239">The range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="461fd-240">La plage du déclencheur analogique, accessible à l’aide de la propriété SpatialInteractionSourceState :: SelectPressedValue, a une plage comprise entre 0 et 1.</span><span class="sxs-lookup"><span data-stu-id="461fd-240">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="461fd-241">La valeur 1 est corrélée avec IsSelectPressed égal à true ; toute autre valeur est corrélée avec IsSelectPressed égal à false.</span><span class="sxs-lookup"><span data-stu-id="461fd-241">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="461fd-242">Suivi articulé</span><span class="sxs-lookup"><span data-stu-id="461fd-242">Articulated hand tracking</span></span>
<span data-ttu-id="461fd-243">L’API Windows Mixed Reality assure une prise en charge complète du suivi articulé, par exemple sur HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="461fd-243">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="461fd-244">Le suivi articulé peut être utilisé pour implémenter la manipulation directe et les modèles d’entrée de point et de validation dans vos applications.</span><span class="sxs-lookup"><span data-stu-id="461fd-244">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="461fd-245">Il peut également être utilisé pour créer des interactions entièrement personnalisées.</span><span class="sxs-lookup"><span data-stu-id="461fd-245">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="461fd-246">Squelette de main</span><span class="sxs-lookup"><span data-stu-id="461fd-246">Hand skeleton</span></span>
<span data-ttu-id="461fd-247">Le suivi articulé fournit un squelette de 25 jointures qui permet de nombreux types différents d’interactions.</span><span class="sxs-lookup"><span data-stu-id="461fd-247">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="461fd-248">La structure fournit cinq jointures pour l’index/le milieu/l’anneau/les petits doigts, quatre articulations pour le pouce et une articulation du poignet.</span><span class="sxs-lookup"><span data-stu-id="461fd-248">The skeleton provides five joints for the index/middle/ring/little fingers, four joints for the thumb, and one wrist joint.</span></span>  <span data-ttu-id="461fd-249">L’articulation du poignet sert de base de la hiérarchie.</span><span class="sxs-lookup"><span data-stu-id="461fd-249">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="461fd-250">L’image suivante illustre la disposition du squelette.</span><span class="sxs-lookup"><span data-stu-id="461fd-250">The following picture illustrates the layout of the skeleton.</span></span>

![Squelette de main](images/hand-skeleton.png)

<span data-ttu-id="461fd-252">Dans la plupart des cas, chaque joint est nommé en fonction du segment qu’il représente.</span><span class="sxs-lookup"><span data-stu-id="461fd-252">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="461fd-253">Étant donné qu’il y a deux segments à chaque articulation, nous utilisons une convention pour nommer chaque jointure en fonction du segment enfant à cet emplacement.</span><span class="sxs-lookup"><span data-stu-id="461fd-253">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="461fd-254">Le segment enfant est défini comme le segment du poignet.</span><span class="sxs-lookup"><span data-stu-id="461fd-254">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="461fd-255">Par exemple, l’articulation « index proximal » contient la position de début de l’index de l’OS proximal et l’orientation de ce segment.</span><span class="sxs-lookup"><span data-stu-id="461fd-255">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="461fd-256">Elle ne contient pas la position de fin du segment.</span><span class="sxs-lookup"><span data-stu-id="461fd-256">It doesn't contain the ending position of the bone.</span></span>  <span data-ttu-id="461fd-257">Si vous en avez besoin, vous pouvez le faire à partir de la jointure suivante dans la hiérarchie, l’articulation « index intermédiaire ».</span><span class="sxs-lookup"><span data-stu-id="461fd-257">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="461fd-258">Outre les 25 articulations hiérarchiques, le système fournit un joint Palm.</span><span class="sxs-lookup"><span data-stu-id="461fd-258">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="461fd-259">La paume n’est généralement pas considérée comme faisant partie de la structure squelettique.</span><span class="sxs-lookup"><span data-stu-id="461fd-259">The palm isn't typically considered part of the skeletal structure.</span></span> <span data-ttu-id="461fd-260">Elle est fournie uniquement comme un moyen pratique d’obtenir la position et l’orientation globales de la main.</span><span class="sxs-lookup"><span data-stu-id="461fd-260">It's provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="461fd-261">Les informations suivantes sont fournies pour chaque jointure :</span><span class="sxs-lookup"><span data-stu-id="461fd-261">The following information is provided for each joint:</span></span>

| <span data-ttu-id="461fd-262">Nom</span><span class="sxs-lookup"><span data-stu-id="461fd-262">Name</span></span> | <span data-ttu-id="461fd-263">Description</span><span class="sxs-lookup"><span data-stu-id="461fd-263">Description</span></span> |
|--- |--- |
|<span data-ttu-id="461fd-264">Position</span><span class="sxs-lookup"><span data-stu-id="461fd-264">Position</span></span> | <span data-ttu-id="461fd-265">position 3D de la jointure, disponible dans n’importe quel système de coordonnées demandé.</span><span class="sxs-lookup"><span data-stu-id="461fd-265">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="461fd-266">Orientation</span><span class="sxs-lookup"><span data-stu-id="461fd-266">Orientation</span></span> | <span data-ttu-id="461fd-267">orientation 3D du segment, disponible dans n’importe quel système de coordonnées demandé.</span><span class="sxs-lookup"><span data-stu-id="461fd-267">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="461fd-268">Radius</span><span class="sxs-lookup"><span data-stu-id="461fd-268">Radius</span></span> | <span data-ttu-id="461fd-269">Distance à la surface de l’apparence à la position conjointe.</span><span class="sxs-lookup"><span data-stu-id="461fd-269">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="461fd-270">Utile pour le paramétrage des interactions directes ou des visualisations qui reposent sur la largeur du doigt.</span><span class="sxs-lookup"><span data-stu-id="461fd-270">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="461fd-271">Précision</span><span class="sxs-lookup"><span data-stu-id="461fd-271">Accuracy</span></span> | <span data-ttu-id="461fd-272">Fournit une indication sur la confiance que le système estime sur les informations de cette articulation.</span><span class="sxs-lookup"><span data-stu-id="461fd-272">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="461fd-273">Vous pouvez accéder aux données squelettes à l’aide d’une fonction sur le [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="461fd-273">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="461fd-274">La fonction est appelée [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)et retourne un objet appelé [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose).</span><span class="sxs-lookup"><span data-stu-id="461fd-274">The function is called [TryGetHandPose](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="461fd-275">Si la source ne prend pas en charge les mains articulées, cette fonction retournera la valeur null.</span><span class="sxs-lookup"><span data-stu-id="461fd-275">If the source doesn't support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="461fd-276">Une fois que vous disposez d’un HandPose, vous pouvez obtenir les données communes actuelles en appelant [TryGetJoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), avec le nom de la jointure qui vous intéresse.</span><span class="sxs-lookup"><span data-stu-id="461fd-276">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you're interested in.</span></span>  <span data-ttu-id="461fd-277">Les données sont retournées sous la forme d’une structure [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) .</span><span class="sxs-lookup"><span data-stu-id="461fd-277">The data is returned as a [JointPose](https://docs.microsoft.com//uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="461fd-278">Le code suivant obtient la position de l’info-bulle de l’index.</span><span class="sxs-lookup"><span data-stu-id="461fd-278">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="461fd-279">La variable *CurrentState* représente une instance de [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="461fd-279">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="461fd-280">Maille manuelle</span><span class="sxs-lookup"><span data-stu-id="461fd-280">Hand mesh</span></span>

<span data-ttu-id="461fd-281">L’API de suivi articulé permet d’obtenir un maillage de handles de triangle entièrement déformable.</span><span class="sxs-lookup"><span data-stu-id="461fd-281">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="461fd-282">Ce maillage peut se déstructurer en temps réel, ainsi que le squelette de la main, et est utile pour la visualisation et les techniques de physique avancées.</span><span class="sxs-lookup"><span data-stu-id="461fd-282">This mesh can deform in real time along with the hand skeleton, and is useful for visualization and advanced physics techniques.</span></span>  <span data-ttu-id="461fd-283">Pour accéder à la maille manuelle, vous devez d’abord créer un objet [HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) en appelant [TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) sur [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span><span class="sxs-lookup"><span data-stu-id="461fd-283">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="461fd-284">Cette opération ne doit être effectuée qu’une seule fois par source, généralement la première fois que vous la voyez.</span><span class="sxs-lookup"><span data-stu-id="461fd-284">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="461fd-285">Cela signifie que vous appellerez cette fonction pour créer un objet HandMeshObserver chaque fois qu’une main entre dans l’angle de la montre.</span><span class="sxs-lookup"><span data-stu-id="461fd-285">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="461fd-286">Il s’agit d’une fonction Async. vous devez donc traiter un peu d’accès concurrentiel ici.</span><span class="sxs-lookup"><span data-stu-id="461fd-286">This is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="461fd-287">Une fois disponible, vous pouvez demander à l’objet HandMeshObserver pour la mémoire tampon d’index de triangle en appelant [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span><span class="sxs-lookup"><span data-stu-id="461fd-287">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="461fd-288">Les index ne changent pas le frame sur le frame, ce qui vous permet de les obtenir et de les mettre en cache pendant la durée de vie de la source.</span><span class="sxs-lookup"><span data-stu-id="461fd-288">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="461fd-289">Les index sont fournis dans l’ordre d’enroulement dans le sens des aiguilles d’une montre.</span><span class="sxs-lookup"><span data-stu-id="461fd-289">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="461fd-290">Le code suivant permet de tourner un std :: thread détaché pour créer l’observateur de maillage et d’extraire le tampon d’index une fois que l’observateur de maillage est disponible.</span><span class="sxs-lookup"><span data-stu-id="461fd-290">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="461fd-291">Il démarre à partir d’une variable appelée *CurrentState*, qui est une instance de [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) représentant une main.</span><span class="sxs-lookup"><span data-stu-id="461fd-291">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="461fd-292">Le démarrage d’un thread détaché n’est qu’une option pour gérer les appels asynchrones.</span><span class="sxs-lookup"><span data-stu-id="461fd-292">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="461fd-293">Vous pouvez également utiliser les nouvelles fonctionnalités de [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) prises en charge par C++/WinRT.</span><span class="sxs-lookup"><span data-stu-id="461fd-293">Alternatively, you could use the new [co_await](https://docs.microsoft.com//windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="461fd-294">Une fois que vous avez un objet HandMeshObserver, vous devez le conserver pendant la durée pendant laquelle son SpatialInteractionSource correspondant est actif.</span><span class="sxs-lookup"><span data-stu-id="461fd-294">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="461fd-295">Ensuite, chaque frame, vous pouvez lui demander la dernière mémoire tampon de vertex qui représente la main en appelant [GetVertexStateForPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) et en passant une instance [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) qui représente le pose pour lequel vous souhaitez obtenir des sommets.</span><span class="sxs-lookup"><span data-stu-id="461fd-295">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com//uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="461fd-296">Chaque vertex de la mémoire tampon a une position et un normal.</span><span class="sxs-lookup"><span data-stu-id="461fd-296">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="461fd-297">Voici un exemple d’obtention de l’ensemble actuel de vertex pour une maille.</span><span class="sxs-lookup"><span data-stu-id="461fd-297">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="461fd-298">Comme précédemment, la variable *CurrentState* représente une instance de [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span><span class="sxs-lookup"><span data-stu-id="461fd-298">As before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com//uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="461fd-299">Contrairement aux jointures squelettes, l’API de maillage de la main ne vous permet pas de spécifier un système de coordonnées pour les vertex.</span><span class="sxs-lookup"><span data-stu-id="461fd-299">In contrast to skeleton joints, the hand mesh API doesn't allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="461fd-300">Au lieu de cela, le [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) spécifie le système de coordonnées dans lequel les vertex sont fournis.</span><span class="sxs-lookup"><span data-stu-id="461fd-300">Instead, the [HandMeshVertexState](https://docs.microsoft.com//uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="461fd-301">Vous pouvez ensuite obtenir une transformation de maillage en appelant [TryGetTransformTo](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) et en spécifiant le système de coordonnées souhaité.</span><span class="sxs-lookup"><span data-stu-id="461fd-301">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying the coordinate system you want.</span></span>  <span data-ttu-id="461fd-302">Vous devez utiliser cette transformation de maille chaque fois que vous travaillez avec les vertex.</span><span class="sxs-lookup"><span data-stu-id="461fd-302">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="461fd-303">Cette approche réduit la surcharge du processeur, en particulier si vous utilisez uniquement la maille à des fins de rendu.</span><span class="sxs-lookup"><span data-stu-id="461fd-303">This approach reduces CPU overhead, especially if you're only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="461fd-304">Mouvements composites de point de regard et de validation</span><span class="sxs-lookup"><span data-stu-id="461fd-304">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="461fd-305">Pour les applications qui utilisent le modèle d’entrée de point de vue et de validation, en particulier sur HoloLens (First Gen), l’API d’entrée spatiale fournit un [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) facultatif qui peut être utilisé pour activer les gestes composites reposant sur l’événement « Select ».</span><span class="sxs-lookup"><span data-stu-id="461fd-305">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="461fd-306">En acheminant les interactions entre le SpatialInteractionManager et le SpatialGestureRecognizer d’un hologramme, les applications peuvent détecter les événements de TAP, de maintien, de manipulation et de navigation uniformément entre les mains, les voix et les périphériques d’entrée spatiales, sans avoir à gérer manuellement les presses et les mises en production.</span><span class="sxs-lookup"><span data-stu-id="461fd-306">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="461fd-307">SpatialGestureRecognizer effectue uniquement une ambiguïté minimale entre l’ensemble de mouvements que vous demandez.</span><span class="sxs-lookup"><span data-stu-id="461fd-307">SpatialGestureRecognizer does only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="461fd-308">Par exemple, si vous demandez simplement TAP, l’utilisateur peut conserver son doigt tant qu’il le souhaite et un TAP continue à se produire.</span><span class="sxs-lookup"><span data-stu-id="461fd-308">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="461fd-309">Si vous demandez un tap-and-hold, une fois que vous avez appuyé sur une seconde du doigt, le geste passe à un blocage et un TAP ne se produit plus.</span><span class="sxs-lookup"><span data-stu-id="461fd-309">If you request both Tap and Hold, after about a second of holding down their finger the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="461fd-310">Pour utiliser SpatialGestureRecognizer, gérez l’événement [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) de SpatialInteractionManager et récupérez le SpatialPointerPose qui y est exposé.</span><span class="sxs-lookup"><span data-stu-id="461fd-310">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="461fd-311">Utilisez le point de vue de la tête du point de vue de l’utilisateur pour croiser les hologrammes et les maillages des surfaces dans l’environnement de l’utilisateur afin de déterminer ce à quoi l’utilisateur a l’intention d’interagir.</span><span class="sxs-lookup"><span data-stu-id="461fd-311">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings to determine what the user is intending to interact with.</span></span> <span data-ttu-id="461fd-312">Ensuite, acheminez le SpatialInteraction dans les arguments d’événement vers le SpatialGestureRecognizer de l’hologramme cible, à l’aide de sa méthode [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) .</span><span class="sxs-lookup"><span data-stu-id="461fd-312">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="461fd-313">Cela commence à interpréter cette interaction en fonction du [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) défini sur ce module de reconnaissance au moment de la création, ou par [TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span><span class="sxs-lookup"><span data-stu-id="461fd-313">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="461fd-314">Sur HoloLens (First Gen), les interactions et les gestes doivent dériver leur ciblage du point de regard de l’utilisateur, plutôt que de rendre ou d’interagir à l’emplacement de la main.</span><span class="sxs-lookup"><span data-stu-id="461fd-314">On HoloLens (first gen), interactions and gestures should derive their targeting from the user's head gaze, rather than rendering or interacting at the hand's location.</span></span> <span data-ttu-id="461fd-315">Une fois qu’une interaction a démarré, les mouvements relatifs de la main peuvent être utilisés pour contrôler le mouvement, comme avec la manipulation ou le mouvement de navigation.</span><span class="sxs-lookup"><span data-stu-id="461fd-315">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="461fd-316">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="461fd-316">See also</span></span>
* [<span data-ttu-id="461fd-317">Suivre de la tête et du regard dans DirectX</span><span class="sxs-lookup"><span data-stu-id="461fd-317">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="461fd-318">Modèle d’entrée de manipulation directe</span><span class="sxs-lookup"><span data-stu-id="461fd-318">Direct manipulation input model</span></span>](../../design/direct-manipulation.md)
* [<span data-ttu-id="461fd-319">Modèle d’entrée de point et de validation</span><span class="sxs-lookup"><span data-stu-id="461fd-319">Point-and-commit input model</span></span>](../../design/point-and-commit.md)
* [<span data-ttu-id="461fd-320">Modèle d’entrée de regard et de validation</span><span class="sxs-lookup"><span data-stu-id="461fd-320">Gaze and commit input model</span></span>](../../design/gaze-and-commit.md)
* [<span data-ttu-id="461fd-321">Contrôleurs de mouvement</span><span class="sxs-lookup"><span data-stu-id="461fd-321">Motion controllers</span></span>](../../design/motion-controllers.md)
