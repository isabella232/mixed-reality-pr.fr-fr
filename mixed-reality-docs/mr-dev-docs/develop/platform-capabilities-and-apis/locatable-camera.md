---
title: Appareil photo localisable
description: Informations générales sur la caméra HoloLens frontale, son fonctionnement et les profils et résolutions disponibles pour les développeurs.
author: cdedmonds
ms.author: wguyman
ms.date: 06/12/2019
ms.topic: article
keywords: appareil photo, hololens, caméra couleur, frontal, hololens 2, CV, vision par ordinateur, fiduciaire, marqueurs, code QR, QR, photo, vidéo
ms.openlocfilehash: 992258a38b78e9f36e873f7c478d2b6e6f0e3785
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 10/03/2020
ms.locfileid: "91679934"
---
# <a name="locatable-camera"></a><span data-ttu-id="eb474-104">Appareil photo localisable</span><span class="sxs-lookup"><span data-stu-id="eb474-104">Locatable camera</span></span>

<span data-ttu-id="eb474-105">HoloLens intègre une caméra universelle montée sur l’avant de l’appareil, ce qui permet aux applications de voir ce que l’utilisateur voit.</span><span class="sxs-lookup"><span data-stu-id="eb474-105">HoloLens includes a world-facing camera mounted on the front of the device, which enables apps to see what the user sees.</span></span> <span data-ttu-id="eb474-106">Les développeurs ont accès à l’appareil photo et le contrôle de ce dernier, tout comme pour les caméras couleur sur les smartphones, les ordinateurs portables ou les ordinateurs de bureau.</span><span class="sxs-lookup"><span data-stu-id="eb474-106">Developers have access to and control of the camera, just as they would for color cameras on smartphones, portables, or desktops.</span></span> <span data-ttu-id="eb474-107">Les mêmes API Universal Windows [Media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) et Windows Media Foundation qui fonctionnent sur les appareils mobiles et de bureau sur HoloLens.</span><span class="sxs-lookup"><span data-stu-id="eb474-107">The same universal windows [media capture](https://msdn.microsoft.com/library/windows/apps/windows.media.capture.mediacapture.aspx) and windows media foundation APIs that work on mobile and desktop work on HoloLens.</span></span> <span data-ttu-id="eb474-108">Unity [a également encapsulé ces API Windows](../unity/locatable-camera-in-unity.md) pour simplifier l’utilisation simple de l’appareil photo sur HoloLens pour des tâches telles que la mise en place de photos et vidéos normales (avec ou sans hologrammes) et la localisation de la caméra dans et la perspective sur la scène.</span><span class="sxs-lookup"><span data-stu-id="eb474-108">Unity [has also wrapped these windows APIs](../unity/locatable-camera-in-unity.md) to abstract simple usage of the camera on HoloLens for tasks such as taking regular photos and videos (with or without holograms) and locating the camera's position in and perspective on the scene.</span></span>

## <a name="device-camera-information"></a><span data-ttu-id="eb474-109">Informations sur l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="eb474-109">Device camera information</span></span>

### <a name="hololens-first-generation"></a><span data-ttu-id="eb474-110">HoloLens (première génération)</span><span class="sxs-lookup"><span data-stu-id="eb474-110">HoloLens (first-generation)</span></span>

* <span data-ttu-id="eb474-111">Correction de l’appareil photo/vidéo (PV) avec balance des blancs automatique, exposition automatique et pipeline de traitement d’image complète.</span><span class="sxs-lookup"><span data-stu-id="eb474-111">Fixed focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="eb474-112">La lumière blanche sur la confidentialité dans le monde s’illumine quand l’appareil photo est actif</span><span class="sxs-lookup"><span data-stu-id="eb474-112">White Privacy LED facing the world will illuminate whenever the camera is active</span></span>
* <span data-ttu-id="eb474-113">L’appareil photo prend en charge les modes suivants (tous les modes sont des proportions 16:9) à 30, 24, 20, 15 et 5 i/s :</span><span class="sxs-lookup"><span data-stu-id="eb474-113">The camera supports the following modes (all modes are 16:9 aspect ratio) at 30, 24, 20, 15, and 5 fps:</span></span>

  |  <span data-ttu-id="eb474-114">Vidéo</span><span class="sxs-lookup"><span data-stu-id="eb474-114">Video</span></span>  |  <span data-ttu-id="eb474-115">PRÉVERSION</span><span class="sxs-lookup"><span data-stu-id="eb474-115">Preview</span></span>  |  <span data-ttu-id="eb474-116">Subsist</span><span class="sxs-lookup"><span data-stu-id="eb474-116">Still</span></span>  |  <span data-ttu-id="eb474-117">Champ horizontal de l’affichage (H-angle d’affichage)</span><span class="sxs-lookup"><span data-stu-id="eb474-117">Horizontal Field of View (H-FOV)</span></span> |  <span data-ttu-id="eb474-118">Utilisation suggérée</span><span class="sxs-lookup"><span data-stu-id="eb474-118">Suggested usage</span></span> | 
  |----------|----------|----------|----------|----------|
  |  <span data-ttu-id="eb474-119">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="eb474-119">1280x720</span></span> |  <span data-ttu-id="eb474-120">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="eb474-120">1280x720</span></span> |  <span data-ttu-id="eb474-121">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="eb474-121">1280x720</span></span> |  <span data-ttu-id="eb474-122">45deg</span><span class="sxs-lookup"><span data-stu-id="eb474-122">45deg</span></span>  |  <span data-ttu-id="eb474-123">(mode par défaut avec stabilisation vidéo)</span><span class="sxs-lookup"><span data-stu-id="eb474-123">(default mode with video stabilization)</span></span> | 
  |  <span data-ttu-id="eb474-124">N/A</span><span class="sxs-lookup"><span data-stu-id="eb474-124">N/A</span></span> |  <span data-ttu-id="eb474-125">N/A</span><span class="sxs-lookup"><span data-stu-id="eb474-125">N/A</span></span> |  <span data-ttu-id="eb474-126">2048x1152</span><span class="sxs-lookup"><span data-stu-id="eb474-126">2048x1152</span></span> |  <span data-ttu-id="eb474-127">67deg</span><span class="sxs-lookup"><span data-stu-id="eb474-127">67deg</span></span> |  <span data-ttu-id="eb474-128">Image toujours la plus haute résolution</span><span class="sxs-lookup"><span data-stu-id="eb474-128">Highest resolution still image</span></span> | 
  |  <span data-ttu-id="eb474-129">1408x792</span><span class="sxs-lookup"><span data-stu-id="eb474-129">1408x792</span></span> |  <span data-ttu-id="eb474-130">1408x792</span><span class="sxs-lookup"><span data-stu-id="eb474-130">1408x792</span></span> |  <span data-ttu-id="eb474-131">1408x792</span><span class="sxs-lookup"><span data-stu-id="eb474-131">1408x792</span></span> |  <span data-ttu-id="eb474-132">48deg</span><span class="sxs-lookup"><span data-stu-id="eb474-132">48deg</span></span> |  <span data-ttu-id="eb474-133">Résolution de suranalyse (remplissage) avant la stabilisation vidéo</span><span class="sxs-lookup"><span data-stu-id="eb474-133">Overscan (padding) resolution before video stabilization</span></span> | 
  |  <span data-ttu-id="eb474-134">1344x756</span><span class="sxs-lookup"><span data-stu-id="eb474-134">1344x756</span></span> |  <span data-ttu-id="eb474-135">1344x756</span><span class="sxs-lookup"><span data-stu-id="eb474-135">1344x756</span></span> |  <span data-ttu-id="eb474-136">1344x756</span><span class="sxs-lookup"><span data-stu-id="eb474-136">1344x756</span></span> |  <span data-ttu-id="eb474-137">67deg</span><span class="sxs-lookup"><span data-stu-id="eb474-137">67deg</span></span> |  <span data-ttu-id="eb474-138">Mode vidéo grand angle avec suranalyse</span><span class="sxs-lookup"><span data-stu-id="eb474-138">Large FOV video mode with overscan</span></span> | 
  |  <span data-ttu-id="eb474-139">896x504</span><span class="sxs-lookup"><span data-stu-id="eb474-139">896x504</span></span> |  <span data-ttu-id="eb474-140">896x504</span><span class="sxs-lookup"><span data-stu-id="eb474-140">896x504</span></span> |  <span data-ttu-id="eb474-141">896x504</span><span class="sxs-lookup"><span data-stu-id="eb474-141">896x504</span></span> |  <span data-ttu-id="eb474-142">48deg</span><span class="sxs-lookup"><span data-stu-id="eb474-142">48deg</span></span> |  <span data-ttu-id="eb474-143">Mode faible puissance/faible résolution pour les tâches de traitement des images</span><span class="sxs-lookup"><span data-stu-id="eb474-143">Low power / Low resolution mode for image processing tasks</span></span> | 

### <a name="hololens-2"></a><span data-ttu-id="eb474-144">HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="eb474-144">HoloLens 2</span></span>

* <span data-ttu-id="eb474-145">Appareil photo/vidéo (PV) de focalisation automatique avec balance des blancs automatique, exposition automatique et pipeline de traitement d’image complète.</span><span class="sxs-lookup"><span data-stu-id="eb474-145">Auto-focus photo/video (PV) camera with auto white balance, auto exposure, and full image processing pipeline.</span></span>
* <span data-ttu-id="eb474-146">La lumière blanche sur la confidentialité dans le monde s’illumine quand l’appareil photo est actif.</span><span class="sxs-lookup"><span data-stu-id="eb474-146">White Privacy LED facing the world will illuminate whenever the camera is active.</span></span>
* <span data-ttu-id="eb474-147">HoloLens 2 prend en charge différents profils d’appareil photo.</span><span class="sxs-lookup"><span data-stu-id="eb474-147">HoloLens 2 supports different camera profiles.</span></span> <span data-ttu-id="eb474-148">Découvrez comment [découvrir et sélectionner les fonctionnalités de l’appareil photo](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span><span class="sxs-lookup"><span data-stu-id="eb474-148">Learn how to [discover and select camera capabilities](https://docs.microsoft.com//windows/uwp/audio-video-camera/camera-profiles).</span></span>
* <span data-ttu-id="eb474-149">L’appareil photo prend en charge les profils et résolutions suivants (tous les modes vidéo sont des proportions 16:9) :</span><span class="sxs-lookup"><span data-stu-id="eb474-149">The camera supports the following profiles and resolutions (all video modes are 16:9 aspect ratio):</span></span>
  
  | <span data-ttu-id="eb474-150">Profil</span><span class="sxs-lookup"><span data-stu-id="eb474-150">Profile</span></span>                                         | <span data-ttu-id="eb474-151">Vidéo</span><span class="sxs-lookup"><span data-stu-id="eb474-151">Video</span></span>     | <span data-ttu-id="eb474-152">PRÉVERSION</span><span class="sxs-lookup"><span data-stu-id="eb474-152">Preview</span></span>   | <span data-ttu-id="eb474-153">Subsist</span><span class="sxs-lookup"><span data-stu-id="eb474-153">Still</span></span>     | <span data-ttu-id="eb474-154">Fréquences d’images</span><span class="sxs-lookup"><span data-stu-id="eb474-154">Frame rates</span></span> | <span data-ttu-id="eb474-155">Champ horizontal de l’affichage (H-angle d’affichage)</span><span class="sxs-lookup"><span data-stu-id="eb474-155">Horizontal Field of View (H-FOV)</span></span> | <span data-ttu-id="eb474-156">Utilisation suggérée</span><span class="sxs-lookup"><span data-stu-id="eb474-156">Suggested usage</span></span>                             |
  |-------------------------------------------------|-----------|-----------|-----------|-------------|----------------------------------|---------------------------------------------|
  | <span data-ttu-id="eb474-157">Hérité, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="eb474-157">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="eb474-158">2272x1278</span><span class="sxs-lookup"><span data-stu-id="eb474-158">2272x1278</span></span> | <span data-ttu-id="eb474-159">2272x1278</span><span class="sxs-lookup"><span data-stu-id="eb474-159">2272x1278</span></span> |           | <span data-ttu-id="eb474-160">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-160">15,30</span></span>       | <span data-ttu-id="eb474-161">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-161">64.69</span></span>                            | <span data-ttu-id="eb474-162">Enregistrement vidéo de haute qualité</span><span class="sxs-lookup"><span data-stu-id="eb474-162">High quality video recording</span></span>                |
  | <span data-ttu-id="eb474-163">Hérité, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="eb474-163">Legacy,0  BalancedVideoAndPhoto,100</span></span>             | <span data-ttu-id="eb474-164">896x504</span><span class="sxs-lookup"><span data-stu-id="eb474-164">896x504</span></span>   | <span data-ttu-id="eb474-165">896x504</span><span class="sxs-lookup"><span data-stu-id="eb474-165">896x504</span></span>   |           | <span data-ttu-id="eb474-166">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-166">15,30</span></span>       | <span data-ttu-id="eb474-167">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-167">64.69</span></span>                            | <span data-ttu-id="eb474-168">Aperçu du flux pour la capture de photos de haute qualité</span><span class="sxs-lookup"><span data-stu-id="eb474-168">Preview stream for high quality photo capture</span></span> |
  | <span data-ttu-id="eb474-169">Hérité, 0 BalancedVideoAndPhoto, 100</span><span class="sxs-lookup"><span data-stu-id="eb474-169">Legacy,0  BalancedVideoAndPhoto,100</span></span>             |           |           | <span data-ttu-id="eb474-170">3904x2196</span><span class="sxs-lookup"><span data-stu-id="eb474-170">3904x2196</span></span> |             | <span data-ttu-id="eb474-171">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-171">64.69</span></span>                            | <span data-ttu-id="eb474-172">Capture photo de haute qualité</span><span class="sxs-lookup"><span data-stu-id="eb474-172">High quality photo capture</span></span>                  |
  | <span data-ttu-id="eb474-173">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-173">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="eb474-174">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb474-174">1952x1100</span></span> | <span data-ttu-id="eb474-175">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb474-175">1952x1100</span></span> | <span data-ttu-id="eb474-176">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb474-176">1952x1100</span></span> | <span data-ttu-id="eb474-177">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-177">15,30</span></span>       | <span data-ttu-id="eb474-178">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-178">64.69</span></span>                            | <span data-ttu-id="eb474-179">Scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-179">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="eb474-180">BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-180">BalancedVideoAndPhoto,120</span></span>                       | <span data-ttu-id="eb474-181">1504x846</span><span class="sxs-lookup"><span data-stu-id="eb474-181">1504x846</span></span>  | <span data-ttu-id="eb474-182">1504x846</span><span class="sxs-lookup"><span data-stu-id="eb474-182">1504x846</span></span>  |           | <span data-ttu-id="eb474-183">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-183">15,30</span></span>       | <span data-ttu-id="eb474-184">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-184">64.69</span></span>                            | <span data-ttu-id="eb474-185">Scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-185">Long duration scenarios</span></span>                     |
  | <span data-ttu-id="eb474-186">Visioconférence, 100</span><span class="sxs-lookup"><span data-stu-id="eb474-186">VideoConferencing,100</span></span>                           | <span data-ttu-id="eb474-187">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb474-187">1952x1100</span></span> | <span data-ttu-id="eb474-188">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb474-188">1952x1100</span></span> | <span data-ttu-id="eb474-189">1952x1100</span><span class="sxs-lookup"><span data-stu-id="eb474-189">1952x1100</span></span> | <span data-ttu-id="eb474-190">15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="eb474-190">15,30,60</span></span>    | <span data-ttu-id="eb474-191">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-191">64.69</span></span>                            | <span data-ttu-id="eb474-192">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-192">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-193">Visioconférence, 100</span><span class="sxs-lookup"><span data-stu-id="eb474-193">Videoconferencing,100</span></span>                           | <span data-ttu-id="eb474-194">1504x846</span><span class="sxs-lookup"><span data-stu-id="eb474-194">1504x846</span></span>  | <span data-ttu-id="eb474-195">1504x846</span><span class="sxs-lookup"><span data-stu-id="eb474-195">1504x846</span></span>  |           | <span data-ttu-id="eb474-196">5, 15, 30, 60</span><span class="sxs-lookup"><span data-stu-id="eb474-196">5,15,30,60</span></span>  | <span data-ttu-id="eb474-197">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-197">64.69</span></span>                            | <span data-ttu-id="eb474-198">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-198">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-199">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-199">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-200">1920 x 1080</span><span class="sxs-lookup"><span data-stu-id="eb474-200">1920x1080</span></span> | <span data-ttu-id="eb474-201">1920 x 1080</span><span class="sxs-lookup"><span data-stu-id="eb474-201">1920x1080</span></span> | <span data-ttu-id="eb474-202">1920 x 1080</span><span class="sxs-lookup"><span data-stu-id="eb474-202">1920x1080</span></span> | <span data-ttu-id="eb474-203">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-203">15,30</span></span>       | <span data-ttu-id="eb474-204">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-204">64.69</span></span>                            | <span data-ttu-id="eb474-205">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-205">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-206">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-206">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-207">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="eb474-207">1280x720</span></span>  | <span data-ttu-id="eb474-208">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="eb474-208">1280x720</span></span>  | <span data-ttu-id="eb474-209">1280 x 720</span><span class="sxs-lookup"><span data-stu-id="eb474-209">1280x720</span></span>  | <span data-ttu-id="eb474-210">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-210">15,30</span></span>       | <span data-ttu-id="eb474-211">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-211">64.69</span></span>                            | <span data-ttu-id="eb474-212">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-212">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-213">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-213">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-214">1128x636</span><span class="sxs-lookup"><span data-stu-id="eb474-214">1128x636</span></span>  |           |           | <span data-ttu-id="eb474-215">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-215">15,30</span></span>       | <span data-ttu-id="eb474-216">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-216">64.69</span></span>                            | <span data-ttu-id="eb474-217">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-217">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-218">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-218">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-219">960 x 540</span><span class="sxs-lookup"><span data-stu-id="eb474-219">960x540</span></span>   |           |           | <span data-ttu-id="eb474-220">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-220">15,30</span></span>       | <span data-ttu-id="eb474-221">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-221">64.69</span></span>                            | <span data-ttu-id="eb474-222">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-222">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-223">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-223">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-224">760x428</span><span class="sxs-lookup"><span data-stu-id="eb474-224">760x428</span></span>   |           |           | <span data-ttu-id="eb474-225">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-225">15,30</span></span>       | <span data-ttu-id="eb474-226">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-226">64.69</span></span>                            | <span data-ttu-id="eb474-227">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-227">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-228">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-228">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-229">640 x 360</span><span class="sxs-lookup"><span data-stu-id="eb474-229">640x360</span></span>   |           |           | <span data-ttu-id="eb474-230">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-230">15,30</span></span>       | <span data-ttu-id="eb474-231">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-231">64.69</span></span>                            | <span data-ttu-id="eb474-232">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-232">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-233">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-233">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-234">500x282</span><span class="sxs-lookup"><span data-stu-id="eb474-234">500x282</span></span>   |           |           | <span data-ttu-id="eb474-235">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-235">15,30</span></span>       | <span data-ttu-id="eb474-236">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-236">64.69</span></span>                            | <span data-ttu-id="eb474-237">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-237">Video conferencing, long duration scenarios</span></span> |
  | <span data-ttu-id="eb474-238">Visioconférence, 100 BalancedVideoAndPhoto, 120</span><span class="sxs-lookup"><span data-stu-id="eb474-238">Videoconferencing,100 BalancedVideoAndPhoto,120</span></span> | <span data-ttu-id="eb474-239">424x240</span><span class="sxs-lookup"><span data-stu-id="eb474-239">424x240</span></span>   |           |           | <span data-ttu-id="eb474-240">15, 30</span><span class="sxs-lookup"><span data-stu-id="eb474-240">15,30</span></span>       | <span data-ttu-id="eb474-241">64,69</span><span class="sxs-lookup"><span data-stu-id="eb474-241">64.69</span></span>                            | <span data-ttu-id="eb474-242">Vidéoconférence, scénarios de longue durée</span><span class="sxs-lookup"><span data-stu-id="eb474-242">Video conferencing, long duration scenarios</span></span> |

> [!NOTE]
> <span data-ttu-id="eb474-243">Les clients peuvent tirer parti de la capture de la [réalité mixte](../../mixed-reality-capture.md) pour prendre des vidéos ou des photos de votre application, notamment des hologrammes et une stabilisation vidéo.</span><span class="sxs-lookup"><span data-stu-id="eb474-243">Customers can leverage [mixed reality capture](../../mixed-reality-capture.md) to take videos or photos of your app, which include holograms and video stabilization.</span></span>
>
><span data-ttu-id="eb474-244">En tant que développeur, vous devez tenir compte de certaines considérations lors de la création de votre application si vous souhaitez qu’elle apparaisse aussi bonne que possible quand un client capture du contenu.</span><span class="sxs-lookup"><span data-stu-id="eb474-244">As a developer, there are considerations you should take into account when creating your app if you want it to look as good as possible when a customer captures content.</span></span> <span data-ttu-id="eb474-245">Vous pouvez également activer (et personnaliser) la capture de la réalité mixte à partir de directement dans votre application.</span><span class="sxs-lookup"><span data-stu-id="eb474-245">You can also enable (and customize) mixed reality capture from directly within your app.</span></span> <span data-ttu-id="eb474-246">En savoir plus sur la [capture de la réalité mixte pour les développeurs](mixed-reality-capture-for-developers.md).</span><span class="sxs-lookup"><span data-stu-id="eb474-246">Learn more at [mixed reality capture for developers](mixed-reality-capture-for-developers.md).</span></span>

## <a name="locating-the-device-camera-in-the-world"></a><span data-ttu-id="eb474-247">Localisation de l’appareil photo de l’appareil dans le monde</span><span class="sxs-lookup"><span data-stu-id="eb474-247">Locating the Device Camera in the World</span></span>

<span data-ttu-id="eb474-248">Lorsque HoloLens prend des photos et des vidéos, les images capturées incluent l’emplacement de la caméra dans le monde, ainsi que le modèle de lentille de l’appareil photo.</span><span class="sxs-lookup"><span data-stu-id="eb474-248">When HoloLens takes photos and videos, the captured frames include the location of the camera in the world, as well as the lens model of the camera.</span></span> <span data-ttu-id="eb474-249">Cela permet aux applications de connaître la position de la caméra dans le monde réel pour les scénarios de création d’images augmentés.</span><span class="sxs-lookup"><span data-stu-id="eb474-249">This allows applications to reason about the position of the camera in the real world for augmented imaging scenarios.</span></span> <span data-ttu-id="eb474-250">Les développeurs peuvent déployer de manière créative leurs propres scénarios à l’aide de leur traitement d’image préféré ou de leurs bibliothèques de vision d’ordinateur personnalisées.</span><span class="sxs-lookup"><span data-stu-id="eb474-250">Developers can creatively roll their own scenarios using their favorite image processing or custom computer vision libraries.</span></span>

<span data-ttu-id="eb474-251">La « caméra » dans la documentation HoloLens peut faire référence à la « caméra de jeu virtuelle » (le frustum rendu de l’application à).</span><span class="sxs-lookup"><span data-stu-id="eb474-251">"Camera" elsewhere in HoloLens documentation may refer to the "virtual game camera" (the frustum the app renders to).</span></span> <span data-ttu-id="eb474-252">Sauf indication contraire, « Camera » sur cette page fait référence à la caméra de couleurs RVB réelle.</span><span class="sxs-lookup"><span data-stu-id="eb474-252">Unless denoted otherwise, "camera" on this page refers to the real-world RGB color camera.</span></span>

### <a name="using-unity"></a><span data-ttu-id="eb474-253">Utilisation de Unity</span><span class="sxs-lookup"><span data-stu-id="eb474-253">Using Unity</span></span>

<span data-ttu-id="eb474-254">Pour passer des « CameraIntrinsics » et « CameraCoordinateSystem » à votre système de coordonnées de l’application/du monde, suivez les instructions de l’article [appareil photo localisable dans Unity](../unity/locatable-camera-in-unity.md) .</span><span class="sxs-lookup"><span data-stu-id="eb474-254">To go from the 'CameraIntrinsics' and 'CameraCoordinateSystem' to your application/world coordinate system, follow the instructions in the [Locatable camera in Unity](../unity/locatable-camera-in-unity.md) article.</span></span>  <span data-ttu-id="eb474-255">CameraToWorldMatrix est automatiquement fourni par la classe PhotoCaptureFrame. vous n’avez donc pas à vous soucier des transformations CameraCoordinateSystem décrites ci-dessous.</span><span class="sxs-lookup"><span data-stu-id="eb474-255">CameraToWorldMatrix is automatically provided by PhotoCaptureFrame class, and so you don't need to worry about the CameraCoordinateSystem transforms discussed below.</span></span>

### <a name="using-mediaframereference"></a><span data-ttu-id="eb474-256">Utilisation de MediaFrameReference</span><span class="sxs-lookup"><span data-stu-id="eb474-256">Using MediaFrameReference</span></span>

<span data-ttu-id="eb474-257">Ces instructions s’appliquent si vous utilisez la classe [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) pour lire des images d’images à partir de l’appareil photo.</span><span class="sxs-lookup"><span data-stu-id="eb474-257">These instructions apply if you are using the [MediaFrameReference](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference) class to read image frames from the camera.</span></span>

<span data-ttu-id="eb474-258">Chaque image (qu’il s’agisse d’une photo ou d’une vidéo) comprend un [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) enraciné à l’appareil photo au moment de la capture, qui est accessible à l’aide de la propriété [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) de votre [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span><span class="sxs-lookup"><span data-stu-id="eb474-258">Each image frame (whether photo or video) includes a [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) rooted at the camera at the time of capture, which can be accessed using the [CoordinateSystem](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.mediaframereference.coordinatesystem#Windows_Media_Capture_Frames_MediaFrameReference_CoordinateSystem) property of your [MediaFrameReference](https://docs.microsoft.com//uwp/api/Windows.Media.Capture.Frames.MediaFrameReference).</span></span> <span data-ttu-id="eb474-259">En outre, chaque frame contient une description du modèle d’objectif de l’appareil photo, qui se trouve dans la propriété [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) .</span><span class="sxs-lookup"><span data-stu-id="eb474-259">In addition, each frame contains a description of the camera lens model, which can be found in the [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) property.</span></span> <span data-ttu-id="eb474-260">Ensemble, ces transformations définissent pour chaque pixel un rayon dans l’espace 3D représentant le chemin emprunté par les photons qui ont produit le pixel.</span><span class="sxs-lookup"><span data-stu-id="eb474-260">Together, these transforms define for each pixel a ray in 3D space representing the path taken by the photons that produced the pixel.</span></span> <span data-ttu-id="eb474-261">Ces rayons peuvent être liés à d’autres contenus dans l’application en obtenant la transformation du système de coordonnées du cadre vers un autre système de coordonnées (par exemple, à partir d’une [image stationnaire de référence](../../design/coordinate-systems.md#stationary-frame-of-reference)).</span><span class="sxs-lookup"><span data-stu-id="eb474-261">These rays can be related to other content in the app by obtaining the transform from the frame's coordinate system to some other coordinate system (e.g. from a [stationary frame of reference](../../design/coordinate-systems.md#stationary-frame-of-reference)).</span></span> <span data-ttu-id="eb474-262">Pour résumer, chaque frame d’image fournit les éléments suivants :</span><span class="sxs-lookup"><span data-stu-id="eb474-262">To summarize, each image frame provides the following:</span></span>
* <span data-ttu-id="eb474-263">Données de pixels (au format RGB/NV12/JPEG/etc.)</span><span class="sxs-lookup"><span data-stu-id="eb474-263">Pixel Data (in RGB/NV12/JPEG/etc. format)</span></span>
* <span data-ttu-id="eb474-264">Un [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) à partir de l’emplacement de capture</span><span class="sxs-lookup"><span data-stu-id="eb474-264">A [SpatialCoordinateSystem](https://docs.microsoft.com//uwp/api/windows.perception.spatial.spatialcoordinatesystem) from the location of capture</span></span>
* <span data-ttu-id="eb474-265">Une classe [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) contenant le mode de l’objectif de l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="eb474-265">A [CameraIntrinsics](https://docs.microsoft.com//uwp/api/windows.media.capture.frames.videomediaframe.cameraintrinsics#Windows_Media_Capture_Frames_VideoMediaFrame_CameraIntrinsics) class containing the lens mode of the camera</span></span>

<span data-ttu-id="eb474-266">L' [exemple HolographicFaceTracking](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) illustre la manière assez simple d’interroger la transformation entre le système de coordonnées de l’appareil photo et vos propres systèmes de coordonnées de l’application.</span><span class="sxs-lookup"><span data-stu-id="eb474-266">The [HolographicFaceTracking sample](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking) shows the fairly straightforward way to query for the transform between the camera's coordinate system and your own application coordinate systems.</span></span>

### <a name="using-media-foundation"></a><span data-ttu-id="eb474-267">Utilisation de Media Foundation</span><span class="sxs-lookup"><span data-stu-id="eb474-267">Using Media Foundation</span></span>

<span data-ttu-id="eb474-268">Si vous utilisez Media Foundation directement pour lire des images d’images à partir de l’appareil photo, vous pouvez utiliser l’attribut [MFSampleExtension_CameraExtrinsics](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) de chaque frame et [MFSampleExtension_PinholeCameraIntrinsics attribut](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) pour rechercher des frames de caméra par rapport aux autres systèmes de coordonnées de votre application, comme illustré dans cet exemple de code :</span><span class="sxs-lookup"><span data-stu-id="eb474-268">If you are using Media Foundation directly to read image frames from the camera, you can use each frame's [MFSampleExtension_CameraExtrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-cameraextrinsics) and [MFSampleExtension_PinholeCameraIntrinsics attribute](https://docs.microsoft.com/windows/win32/medfound/mfsampleextension-pinholecameraintrinsics) to locate camera frames relative to your application's other coordinate systems, as shown in this sample code:</span></span>

```cpp
#include <winrt/windows.perception.spatial.preview.h>
#include <mfapi.h>
#include <mfidl.h>
 
using namespace winrt::Windows::Foundation;
using namespace winrt::Windows::Foundation::Numerics;
using namespace winrt::Windows::Perception;
using namespace winrt::Windows::Perception::Spatial;
using namespace winrt::Windows::Perception::Spatial::Preview;
 
class CameraFrameLocator
{
public:
    struct CameraFrameLocation
    {
        SpatialCoordinateSystem CoordinateSystem;
        float4x4 CameraViewToCoordinateSytemTransform;
        MFPinholeCameraIntrinsics Intrinsics;
    };
 
    std::optional<CameraFrameLocation> TryLocateCameraFrame(IMFSample* pSample)
    {
        MFCameraExtrinsics cameraExtrinsics;
        MFPinholeCameraIntrinsics cameraIntrinsics;
        UINT32 sizeCameraExtrinsics = 0;
        UINT32 sizeCameraIntrinsics = 0;
        UINT64 sampleTimeHns = 0;
 
        // query sample for calibration and validate
        if (FAILED(pSample->GetUINT64(MFSampleExtension_DeviceTimestamp, &sampleTimeHns)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_CameraExtrinsics, (UINT8*)& cameraExtrinsics, sizeof(cameraExtrinsics), &sizeCameraExtrinsics)) ||
            FAILED(pSample->GetBlob(MFSampleExtension_PinholeCameraIntrinsics, (UINT8*)& cameraIntrinsics, sizeof(cameraIntrinsics), &sizeCameraIntrinsics)) ||
            (sizeCameraExtrinsics != sizeof(cameraExtrinsics)) ||
            (sizeCameraIntrinsics != sizeof(cameraIntrinsics)) ||
            (cameraExtrinsics.TransformCount == 0))
        {
            return std::nullopt;
        }
 
        // compute extrinsic transform
        const auto& calibratedTransform = cameraExtrinsics.CalibratedTransforms[0];
        const GUID& dynamicNodeId = calibratedTransform.CalibrationId;
        const float4x4 cameraToDynamicNode =
            make_float4x4_from_quaternion(quaternion{ calibratedTransform.Orientation.x, calibratedTransform.Orientation.y, calibratedTransform.Orientation.z, calibratedTransform.Orientation.w }) *
            make_float4x4_translation(calibratedTransform.Position.x, calibratedTransform.Position.y, calibratedTransform.Position.z);
 
        // update locator cache for dynamic node
        if (dynamicNodeId != m_currentDynamicNodeId || !m_locator)
        {
            m_locator = SpatialGraphInteropPreview::CreateLocatorForNode(dynamicNodeId);
            if (!m_locator)
            {
                return std::nullopt;
            }
 
            m_frameOfReference = m_locator.CreateAttachedFrameOfReferenceAtCurrentHeading();
            m_currentDynamicNodeId = dynamicNodeId;
        }
 
        // locate dynamic node
        auto timestamp = PerceptionTimestampHelper::FromSystemRelativeTargetTime(TimeSpan{ sampleTimeHns });
        auto coordinateSystem = m_frameOfReference.GetStationaryCoordinateSystemAtTimestamp(timestamp);
        auto location = m_locator.TryLocateAtTimestamp(timestamp, coordinateSystem);
        if (!location)
        {
            return std::nullopt;
        }
 
        const float4x4 dynamicNodeToCoordinateSystem = make_float4x4_from_quaternion(location.Orientation()) * make_float4x4_translation(location.Position());
 
        return CameraFrameLocation{ coordinateSystem, cameraToDynamicNode * dynamicNodeToCoordinateSystem, cameraIntrinsics };
    }

private:
    GUID m_currentDynamicNodeId{ GUID_NULL };
    SpatialLocator m_locator{ nullptr };
    SpatialLocatorAttachedFrameOfReference m_frameOfReference{ nullptr };
};
```

### <a name="distortion-error"></a><span data-ttu-id="eb474-269">Erreur de distorsion</span><span class="sxs-lookup"><span data-stu-id="eb474-269">Distortion Error</span></span>

<span data-ttu-id="eb474-270">Sur HoloLens, les flux vidéo et d’images fixes ne sont pas déformés dans le pipeline de traitement d’image du système avant que les frames ne soient mis à disposition de l’application (le flux de préversion contient les frames déformés d’origine).</span><span class="sxs-lookup"><span data-stu-id="eb474-270">On HoloLens, the video and still image streams are undistorted in the system's image processing pipeline before the frames are made available to the application (the preview stream contains the original distorted frames).</span></span> <span data-ttu-id="eb474-271">Étant donné que seules les CameraIntrinsics sont disponibles, les applications doivent supposer que les images d’images représentent une caméra Pinhole parfaite.</span><span class="sxs-lookup"><span data-stu-id="eb474-271">Because only the CameraIntrinsics are made available, applications must assume image frames represent a perfect pinhole camera.</span></span>

<span data-ttu-id="eb474-272">Sur HoloLens (première génération), la fonction d’intorsion dans le processeur d’images peut toujours provoquer une erreur pouvant atteindre 10 pixels lors de l’utilisation de CameraIntrinsics dans les métadonnées de frame.</span><span class="sxs-lookup"><span data-stu-id="eb474-272">On HoloLens (first-generation), the undistortion function in the image processor may still leave an error of up to 10 pixels when using the CameraIntrinsics in the frame metadata.</span></span> <span data-ttu-id="eb474-273">Dans de nombreux cas d’utilisation, cette erreur n’a pas d’importance, mais si vous alignez des hologrammes sur des affiches/marqueurs réels, par exemple, et que vous remarquez un décalage de <10px (à peu près 11mm pour les hologrammes positionnés sur 2 mètres), cette erreur de distorsion peut en être la cause.</span><span class="sxs-lookup"><span data-stu-id="eb474-273">In many use cases, this error will not matter, but if you are aligning holograms to real world posters/markers, for example, and you notice a <10px offset (roughly 11mm for holograms positioned 2 meters away), this distortion error could be the cause.</span></span> 

## <a name="locatable-camera-usage-scenarios"></a><span data-ttu-id="eb474-274">Scénarios d’utilisation d’appareil photo localisables</span><span class="sxs-lookup"><span data-stu-id="eb474-274">Locatable Camera Usage Scenarios</span></span>

### <a name="show-a-photo-or-video-in-the-world-where-it-was-captured"></a><span data-ttu-id="eb474-275">Afficher une photo ou une vidéo dans le monde où elle a été capturée</span><span class="sxs-lookup"><span data-stu-id="eb474-275">Show a photo or video in the world where it was captured</span></span>

<span data-ttu-id="eb474-276">Les cadres de l’appareil photo sont fournis avec une transformation « caméra à toute la vie », qui peut être utilisée pour indiquer exactement où se trouvait l’appareil lorsque l’image a été prise.</span><span class="sxs-lookup"><span data-stu-id="eb474-276">The Device Camera frames come with a "Camera To World" transform, that can be used to show exactly where the device was when the image was taken.</span></span> <span data-ttu-id="eb474-277">Par exemple, vous pouvez positionner une petite icône holographique à cet emplacement (CameraToWorld. MultiplyPoint (Vector3. Zero)) et même dessiner une petite flèche dans la direction vers laquelle l’appareil photo était dirigée (CameraToWorld. MultiplyVector (Vector3. Forward)).</span><span class="sxs-lookup"><span data-stu-id="eb474-277">For example, you could position a small holographic icon at this location (CameraToWorld.MultiplyPoint(Vector3.zero)) and even draw a little arrow in the direction that the camera was facing (CameraToWorld.MultiplyVector(Vector3.forward)).</span></span>

### <a name="tag--pattern--poster--object-tracking"></a><span data-ttu-id="eb474-278">Étiquette/modèle/affiche/suivi d’objet</span><span class="sxs-lookup"><span data-stu-id="eb474-278">Tag / Pattern / Poster / Object Tracking</span></span>

<span data-ttu-id="eb474-279">De nombreuses applications de réalité mixte utilisent une image ou un modèle visuel identifiable pour créer un point de suivi dans l’espace.</span><span class="sxs-lookup"><span data-stu-id="eb474-279">Many mixed reality applications use a recognizable image or visual pattern to create a trackable point in space.</span></span> <span data-ttu-id="eb474-280">Il est ensuite utilisé pour restituer des objets par rapport à ce point ou créer un emplacement connu.</span><span class="sxs-lookup"><span data-stu-id="eb474-280">This is then used to render objects relative to that point or create a known location.</span></span> <span data-ttu-id="eb474-281">Certaines utilisations de HoloLens incluent la recherche d’un objet réel marqué avec des appariés (par exemple, un moniteur TV avec un code QR), la mise en place d’hologrammes sur des personnes fiduciaires et le couplage visuel avec des appareils non-HoloLens tels que des tablettes qui ont été configurés pour communiquer avec HoloLens via le Wi-Fi.</span><span class="sxs-lookup"><span data-stu-id="eb474-281">Some uses for HoloLens include finding a real world object tagged with fiducials (e.g. a TV monitor with a QR code), placing holograms over fiducials, and visually pairing with non-HoloLens devices like tablets that have been setup to communicate with HoloLens via Wi-Fi.</span></span>

<span data-ttu-id="eb474-282">Pour reconnaître un modèle visuel, puis placer cet objet dans l’espace universel des applications, vous avez besoin de quelques éléments :</span><span class="sxs-lookup"><span data-stu-id="eb474-282">To recognize a visual pattern, and then place that object in the applications world space, you'll need a few things:</span></span>
1. <span data-ttu-id="eb474-283">Boîte à outils de reconnaissance de modèle d’image, telle que le code QR, les balises AR, le Finder de visages, les traceurs de cercle, la reconnaissance optique, etc.</span><span class="sxs-lookup"><span data-stu-id="eb474-283">An image pattern recognition toolkit, such as QR code, AR tags, face finder, circle trackers, OCR etc.</span></span>
2. <span data-ttu-id="eb474-284">Collecter les trames d’image au moment de l’exécution et les transmettre à la couche de reconnaissance</span><span class="sxs-lookup"><span data-stu-id="eb474-284">Collect image frames at runtime, and pass them to the recognition layer</span></span>
3. <span data-ttu-id="eb474-285">Déprojetez leurs emplacements d’images dans des positions universelles ou des rayons de monde probables.</span><span class="sxs-lookup"><span data-stu-id="eb474-285">Unproject their image locations back into world positions, or likely world rays.</span></span> 
4. <span data-ttu-id="eb474-286">Positionner vos modèles virtuels sur ces emplacements mondiaux</span><span class="sxs-lookup"><span data-stu-id="eb474-286">Position your virtual models over these world locations</span></span>

<span data-ttu-id="eb474-287">Voici quelques liens importants sur le traitement des images :</span><span class="sxs-lookup"><span data-stu-id="eb474-287">Some important image processing links:</span></span>
* [<span data-ttu-id="eb474-288">OpenCV</span><span class="sxs-lookup"><span data-stu-id="eb474-288">OpenCV</span></span>](https://opencv.org/)
* [<span data-ttu-id="eb474-289">Balises QR</span><span class="sxs-lookup"><span data-stu-id="eb474-289">QR Tags</span></span>](https://en.wikipedia.org/wiki/QR_code)
* [<span data-ttu-id="eb474-290">FaceSDK</span><span class="sxs-lookup"><span data-stu-id="eb474-290">FaceSDK</span></span>](https://research.microsoft.com/projects/facesdk/)
* [<span data-ttu-id="eb474-291">Microsoft Translator</span><span class="sxs-lookup"><span data-stu-id="eb474-291">Microsoft Translator</span></span>](https://www.microsoft.com/translator/business)

<span data-ttu-id="eb474-292">Le maintien d’une fréquence d’images d’application interactive est essentiel, en particulier lors du traitement des algorithmes de reconnaissance d’images à long terme.</span><span class="sxs-lookup"><span data-stu-id="eb474-292">Keeping an interactive application frame-rate is critical, especially when dealing with long-running image recognition algorithms.</span></span> <span data-ttu-id="eb474-293">Pour cette raison, nous utilisons généralement le modèle suivant :</span><span class="sxs-lookup"><span data-stu-id="eb474-293">For this reason, we commonly use the following pattern:</span></span>
1. <span data-ttu-id="eb474-294">Thread principal : gère l’objet Camera</span><span class="sxs-lookup"><span data-stu-id="eb474-294">Main Thread: manages the camera object</span></span>
2. <span data-ttu-id="eb474-295">Thread principal : demande de nouveaux frames (Async)</span><span class="sxs-lookup"><span data-stu-id="eb474-295">Main Thread: requests new frames (async)</span></span>
3. <span data-ttu-id="eb474-296">Thread principal : passer de nouveaux frames au thread de suivi</span><span class="sxs-lookup"><span data-stu-id="eb474-296">Main Thread: pass new frames to tracking thread</span></span>
4. <span data-ttu-id="eb474-297">Thread de suivi : traite l’image pour collecter des points clés</span><span class="sxs-lookup"><span data-stu-id="eb474-297">Tracking Thread: processes image to collect key points</span></span>
5. <span data-ttu-id="eb474-298">Thread principal : déplace le modèle virtuel pour trouver les points clés trouvés</span><span class="sxs-lookup"><span data-stu-id="eb474-298">Main Thread: moves virtual model to match found key points</span></span>
6. <span data-ttu-id="eb474-299">Thread principal : répéter à l’étape 2</span><span class="sxs-lookup"><span data-stu-id="eb474-299">Main Thread: repeat from step 2</span></span>

<span data-ttu-id="eb474-300">Certains systèmes de marqueurs d’images ne fournissent qu’un seul emplacement de pixel (les autres fournissent la transformation complète, auquel cas cette section n’est pas nécessaire), qui équivaut à un rayon d’emplacements possibles.</span><span class="sxs-lookup"><span data-stu-id="eb474-300">Some image marker systems only provide a single pixel location (others provide the full transform in which case this section will not be needed), which equates to a ray of possible locations.</span></span> <span data-ttu-id="eb474-301">Pour atteindre un emplacement 3D unique, nous pouvons ensuite tirer parti de plusieurs rayons et trouver le résultat final en fonction de leur intersection approximative.</span><span class="sxs-lookup"><span data-stu-id="eb474-301">To get to a single 3d location, we can then leverage multiple rays and find the final result by their approximate intersection.</span></span> <span data-ttu-id="eb474-302">Pour ce faire, procédez comme suit :</span><span class="sxs-lookup"><span data-stu-id="eb474-302">To do this, you'll need to:</span></span>
1. <span data-ttu-id="eb474-303">Obtenir une boucle qui collecte plusieurs images d’appareil photo</span><span class="sxs-lookup"><span data-stu-id="eb474-303">Get a loop going collecting multiple camera images</span></span>
2. <span data-ttu-id="eb474-304">Rechercher les points de fonctionnalités associés et leurs rayons mondiaux</span><span class="sxs-lookup"><span data-stu-id="eb474-304">Find the associated feature points, and their world rays</span></span>
3. <span data-ttu-id="eb474-305">Lorsque vous disposez d’un dictionnaire de fonctionnalités, chacun avec plusieurs rayons de monde, vous pouvez utiliser le code suivant pour résoudre l’intersection de ces rayons :</span><span class="sxs-lookup"><span data-stu-id="eb474-305">When you have a dictionary of features, each with multiple world rays, you can use the following code to solve for the intersection of those rays:</span></span>

```
public static Vector3 ClosestPointBetweenRays(
   Vector3 point1, Vector3 normalizedDirection1,
   Vector3 point2, Vector3 normalizedDirection2) {
   float directionProjection = Vector3.Dot(normalizedDirection1, normalizedDirection2);
   if (directionProjection == 1) {
     return point1; // parallel lines
   }
   float projection1 = Vector3.Dot(point2 - point1, normalizedDirection1);
   float projection2 = Vector3.Dot(point2 - point1, normalizedDirection2);
   float distanceAlongLine1 = (projection1 - directionProjection * projection2) / (1 - directionProjection * directionProjection);
   float distanceAlongLine2 = (projection2 - directionProjection * projection1) / (directionProjection * directionProjection - 1);
   Vector3 pointOnLine1 = point1 + distanceAlongLine1 * normalizedDirection1;
   Vector3 pointOnLine2 = point2 + distanceAlongLine2 * normalizedDirection2;
   return Vector3.Lerp(pointOnLine2, pointOnLine1, 0.5f);
 }
```

<span data-ttu-id="eb474-306">À partir de deux ou plusieurs emplacements d’étiquette suivis, vous pouvez positionner une scène modélisée pour l’adapter au scénario actuel de l’utilisateur.</span><span class="sxs-lookup"><span data-stu-id="eb474-306">Given two or more tracked tag locations, you can position a modelled scene to fit the user's current scenario.</span></span> <span data-ttu-id="eb474-307">Si vous ne pouvez pas supposer la gravité, vous aurez besoin de trois emplacements de balises.</span><span class="sxs-lookup"><span data-stu-id="eb474-307">If you can't assume gravity, then you'll need three tag locations.</span></span> <span data-ttu-id="eb474-308">Dans de nombreux cas, nous utilisons un modèle de couleurs simple où les blancs représentent les emplacements de balises suivi en temps réel, et les sphères bleues représentent les emplacements de balise modélisés.</span><span class="sxs-lookup"><span data-stu-id="eb474-308">In many cases, we use a simple color scheme where white spheres represent real-time tracked tag locations, and blue spheres represent modelled tag locations.</span></span> <span data-ttu-id="eb474-309">Cela permet à l’utilisateur de mesurer visuellement la qualité d’alignement.</span><span class="sxs-lookup"><span data-stu-id="eb474-309">This allows the user to visually gauge the alignment quality.</span></span> <span data-ttu-id="eb474-310">Nous supposons l’installation suivante dans toutes nos applications :</span><span class="sxs-lookup"><span data-stu-id="eb474-310">We assume the following setup in all our applications:</span></span>
* <span data-ttu-id="eb474-311">Deux ou plusieurs emplacements de balise modélisés</span><span class="sxs-lookup"><span data-stu-id="eb474-311">Two or more modelled tag locations</span></span>
* <span data-ttu-id="eb474-312">Un « espace d’étalonnage » qui, dans la scène, est le parent des balises</span><span class="sxs-lookup"><span data-stu-id="eb474-312">One 'calibration space' which in the scene is the parent of the tags</span></span>
* <span data-ttu-id="eb474-313">Identificateur de la fonctionnalité de l’appareil photo</span><span class="sxs-lookup"><span data-stu-id="eb474-313">Camera feature identifier</span></span>
* <span data-ttu-id="eb474-314">Comportement qui déplace l’espace d’étalonnage pour aligner les balises modélisées avec les balises en temps réel (nous sommes prudents de déplacer l’espace parent, et non les marqueurs modélisés, car d’autres connexions sont des positions relatives à eux).</span><span class="sxs-lookup"><span data-stu-id="eb474-314">Behavior which moves the calibration space to align the modelled tags with the real-time tags (we are careful to move the parent space, not the modelled markers themselves, because other connect is positions relative to them).</span></span>

```
// In the two tags case:
 Vector3 idealDelta = (realTags[1].EstimatedWorldPos - realTags[0].EstimatedWorldPos);
 Vector3 curDelta = (modelledTags[1].transform.position - modelledTags[0].transform.position);
 if (IsAssumeGravity) {
   idealDelta.y = 0;
   curDelta.y = 0;
 }
 Quaternion deltaRot = Quaternion.FromToRotation(curDelta, idealDelta);
 trans.rotation = Quaternion.LookRotation(deltaRot * trans.forward, trans.up);
 trans.position += realTags[0].EstimatedWorldPos - modelledTags[0].transform.position;
```

### <a name="track-or-identify-tagged-stationary-or-moving-real-world-objectsfaces-using-leds-or-other-recognizer-libraries"></a><span data-ttu-id="eb474-315">Suivre ou identifier des objets/visages à l’aide de voyants ou d’autres bibliothèques de reconnaissance</span><span class="sxs-lookup"><span data-stu-id="eb474-315">Track or Identify Tagged Stationary or Moving real-world objects/faces using LEDs or other recognizer libraries</span></span>

<span data-ttu-id="eb474-316">Exemples :</span><span class="sxs-lookup"><span data-stu-id="eb474-316">Examples:</span></span>
* <span data-ttu-id="eb474-317">Robots industriels avec del (ou codes QR pour des objets en déplacement plus lents)</span><span class="sxs-lookup"><span data-stu-id="eb474-317">Industrial robots with LEDs (or QR codes for slower moving objects)</span></span>
* <span data-ttu-id="eb474-318">Identifier et reconnaître des objets dans la salle</span><span class="sxs-lookup"><span data-stu-id="eb474-318">Identify and recognize objects in the room</span></span>
* <span data-ttu-id="eb474-319">Identifier et reconnaître les personnes de la pièce (par exemple, placer des cartes de contact holographiques sur des visages)</span><span class="sxs-lookup"><span data-stu-id="eb474-319">Identify and recognize people in the room (e.g. place holographic contact cards over faces)</span></span>

## <a name="see-also"></a><span data-ttu-id="eb474-320">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="eb474-320">See also</span></span>
* [<span data-ttu-id="eb474-321">Exemple d’appareil photo localisable</span><span class="sxs-lookup"><span data-stu-id="eb474-321">Locatable camera sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
* [<span data-ttu-id="eb474-322">Appareil photo localisable dans Unity</span><span class="sxs-lookup"><span data-stu-id="eb474-322">Locatable camera in Unity</span></span>](../unity/locatable-camera-in-unity.md)
* [<span data-ttu-id="eb474-323">MRC (Mixed Reality Capture)</span><span class="sxs-lookup"><span data-stu-id="eb474-323">Mixed reality capture</span></span>](../../mixed-reality-capture.md)
* [<span data-ttu-id="eb474-324">Capture de Réalité Mixte pour les développeurs</span><span class="sxs-lookup"><span data-stu-id="eb474-324">Mixed reality capture for developers</span></span>](mixed-reality-capture-for-developers.md)
* [<span data-ttu-id="eb474-325">Présentation de la capture multimédia</span><span class="sxs-lookup"><span data-stu-id="eb474-325">Media capture introduction</span></span>](https://msdn.microsoft.com/library/windows/apps/mt243896.aspx)
* [<span data-ttu-id="eb474-326">Exemple de suivi de visage holographique</span><span class="sxs-lookup"><span data-stu-id="eb474-326">Holographic face tracking sample</span></span>](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HolographicFaceTracking)
