---
title: Atelier de Vision par ordinateur d’applications pour les casques de réalité mixte sur CVPR 2019
description: Vue d’ensemble et planification des applications Vision par ordinateur pour les casques d’écouteurs de réalité mixte, à livrer à la Conférence CVPR le 2019 juin.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: événement, mode de recherche, CVPR, vision par ordinateur, recherche, HoloLens
ms.openlocfilehash: 7768f7a473e4bd98f4a2868161dd3d365bc94fc5c2e5f006f382046b680749a3
ms.sourcegitcommit: a1c086aa83d381129e62f9d8942f0fc889ffcab0
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/05/2021
ms.locfileid: "115195624"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a>Vision par ordinateur des applications pour les casques de réalité mixte

Organisée conjointement avec [CVPR 2019](https://cvpr2019.thecvf.com/)

Long Beach (CA)

17 juin 2019 (après-midi)-Hyatt Regency F


## <a name="organizers"></a>Organisateur
* Marc Pollefeys
* Federica Bogo
* Johannes Schönberger
* Osman Ulusoy

## <a name="overview"></a>Vue d’ensemble

![Image de l’tease](images/cvpr2019_teaser2.jpg)

les casques de réalité mixte tels que le Microsoft HoloLens sont des plateformes puissantes pour développer des applications de vision informatique. HoloLens Le mode de recherche permet à Computer Vision Research sur l’appareil en fournissant un accès à tous les flux de capteur d’images brutes, y compris la profondeur et l’IR. Étant donné que le mode de recherche est désormais disponible depuis le 2018 mai, nous commençons à voir plusieurs démonstrations et applications intéressantes développées pour HoloLens. 

L’objectif de cet atelier est de réunir les étudiants et les chercheurs intéressés par la vision informatique pour les applications de réalité mixte. L’atelier vous permettra de partager des démonstrations et des applications, et d’apprendre les uns avec les autres pour créer ou porter des applications à la réalité mixte. 

Nous encourageons les soumissions de la reconnaissance des objets (centrés sur ego), de la main et des utilisateurs, de la reconnaissance des activités, de la reconstruction 3D, de la présentation des scènes, de la localisation basée sur les capteurs, de la navigation et bien plus encore.

## <a name="paper-submission"></a>Envoi de documents
* Échéance de soumission du document : 17 mai
* Notification aux auteurs : 24 mai

Les envois de documents doivent utiliser le modèle CVPR et sont limités à 4 pages plus références. En outre, nous encourageons les auteurs à envoyer une vidéo présentant leur application.
Notez que les envois de travaux précédemment publiés sont autorisés (y compris le travail accepté pour la Conférence principale CVPR 2019). 

Les envois peuvent être téléchargés vers le CMT : https://cmt3.research.microsoft.com/CVFORMR2019

Un sous-ensemble de documents sera sélectionné pour une présentation orale au cours de l’atelier. Toutefois, nous encourageons fortement tous les auteurs à présenter leur travail pendant la session de démonstration.


## <a name="schedule"></a>Planifier
* 13:30-13:45 : Remarques relatives à l’accueil et à l’ouverture.
* 13:45-14:15 : **discours parlé**: Prof. Marc POLLEFEYS, ETH Zurich/Microsoft. Titre : egocentric Vision par ordinateur sur HoloLens.
* 14:15-14:45 : **discours parlé**: Prof. Kris Kitani, Carnegie Mellon University. Titre : activité egocentric et les prévisions de pose.
* 14:45-15:15 : **discours parlé**: Dr. Yang Liu, Californie Institute of Technology. Titre : alimenter un Assistant cognitif pour aveugle avec une réalité augmentée.
* 15:15-16:15 : les démonstrations et les pauses café.
* 16:15-16:45 : **discours** de la Conférence : Prof. Kristen Grau, Université du Texas à Austin/Facebook ai Research. Titre : interaction de l’objet humain dans la vidéo de première personne.
* 16:45-17:15 : présentations orales :
    * L’inscription a fait une navigation orthopédique simple et autonome avec HoloLens. F. Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.
    * Learning stéréo en parcourant un HoloLens. H. Zhan, Y. Pekelny, O. Ulusoy.
* 17:15-17:30 : notes finales.
